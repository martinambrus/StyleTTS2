{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/yl4579/StyleTTS2/blob/main/Colab/StyleTTS2_Demo_LJSpeech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nm653VK4CG9F"
   },
   "source": [
    "### Install packages and download models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gciBKMqCCLvT"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "if [ ! -d StyleTTS2 ]; then\n",
    "  git clone https://github.com/yl4579/StyleTTS2.git\n",
    "fi\n",
    "cd StyleTTS2\n",
    "pip install --quiet SoundFile torchaudio munch torch pydub pyyaml librosa nltk matplotlib accelerate transformers phonemizer einops einops-exts tqdm typing-extensions noisereduce git+https://github.com/resemble-ai/monotonic_align.git\n",
    "sudo apt-get -y install espeak-ng\n",
    "git lfs install\n",
    "git lfs clone https://huggingface.co/yl4579/StyleTTS2-LJSpeech\n",
    "mv StyleTTS2-LJSpeech/Models .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAA8lx-XCQnM"
   },
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m0XRpbxSCSix"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.isdir(\"Modules\"):\n",
    "    %cd ../\n",
    "\n",
    "!pwd\n",
    "lang_id = 'ar'\n",
    "checkpoint_dir = \"Checkpoint_ar_new_aux_whisper_large\"\n",
    "#checkpoint_dir = \"Models/LJSpeech_cs_wavlm\"\n",
    "#checkpoint_dir = \"Models/LJSpeech_ar_en_whisper\"\n",
    "config_file_name = \"config.yml\"\n",
    "\n",
    "import IPython.display as ipd\n",
    "import torch\n",
    "import noisereduce as nr\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# load packages\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import yaml\n",
    "from munch import Munch\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import librosa\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from models import *\n",
    "from utils import *\n",
    "from text_utils import TextCleaner\n",
    "from phoneme_dictionary import DEFAULT_DICTIONARY_PATH\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "to_mel = torchaudio.transforms.MelSpectrogram(\n",
    "    n_mels=80, n_fft=2048, win_length=1200, hop_length=300)\n",
    "mean, std = -4, 4\n",
    "\n",
    "def length_to_mask(lengths):\n",
    "    mask = torch.arange(lengths.max()).unsqueeze(0).expand(lengths.shape[0], -1).type_as(lengths)\n",
    "    mask = torch.gt(mask+1, lengths.unsqueeze(1))\n",
    "    return mask\n",
    "\n",
    "def preprocess(wave):\n",
    "    wave_tensor = torch.from_numpy(wave).float()\n",
    "    mel_tensor = to_mel(wave_tensor)\n",
    "    mel_tensor = (torch.log(1e-5 + mel_tensor.unsqueeze(0)) - mean) / std\n",
    "    return mel_tensor\n",
    "\n",
    "def compute_style(ref_dicts):\n",
    "    reference_embeddings = {}\n",
    "    for key, path in ref_dicts.items():\n",
    "        wave, sr = librosa.load(path, sr=24000)\n",
    "        audio, index = librosa.effects.trim(wave, top_db=30)\n",
    "        if sr != 24000:\n",
    "            audio = librosa.resample(audio, sr, 24000)\n",
    "        mel_tensor = preprocess(audio).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            ref = model.style_encoder(mel_tensor.unsqueeze(1))\n",
    "        reference_embeddings[key] = (ref.squeeze(1), audio)\n",
    "\n",
    "    return reference_embeddings\n",
    "\n",
    "# load phonemizer\n",
    "import phonemizer\n",
    "global_phonemizer = phonemizer.backend.EspeakBackend(language=lang_id, preserve_punctuation=True, with_stress=True, words_mismatch='ignore')\n",
    "\n",
    "config_path = os.path.join(checkpoint_dir, config_file_name)\n",
    "if not os.path.isfile(config_path):\n",
    "    raise FileNotFoundError(f\"Config file not found: {config_path}\")\n",
    "with open(config_path) as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "dictionary_settings = config.get('data_params', {}).get('phoneme_dictionary_config', {}) or {}\n",
    "dictionary_path = config.get('data_params', {}).get('phoneme_dict_path', DEFAULT_DICTIONARY_PATH)\n",
    "textcleaner = TextCleaner(dictionary_path, dictionary_settings)\n",
    "lang_id = config.get('inference_params', {}).get('phonemizer_language', lang_id)\n",
    "\n",
    "# load pretrained ASR model\n",
    "ASR_config = config.get('ASR_config', False)\n",
    "ASR_path = config.get('ASR_path', False)\n",
    "text_aligner = load_ASR_models(ASR_path, ASR_config)\n",
    "\n",
    "# load pretrained F0 model\n",
    "F0_path = config.get('F0_path', False)\n",
    "pitch_extractor = load_F0_models(F0_path)\n",
    "\n",
    "# load BERT model\n",
    "from Utils.PLBERT.util import load_plbert\n",
    "BERT_path = config.get('PLBERT_dir', False)\n",
    "plbert = load_plbert(BERT_path)\n",
    "\n",
    "model = build_model(recursive_munch(config['model_params']), text_aligner, pitch_extractor, plbert)\n",
    "_ = [model[key].eval() for key in model]\n",
    "_ = [model[key].to(device) for key in model]\n",
    "\n",
    "sigma_data = (\n",
    "    config.get('model_params', {})\n",
    "          .get('diffusion', {})\n",
    "          .get('dist', {})\n",
    "          .get('sigma_data')\n",
    ")\n",
    "if sigma_data is not None:\n",
    "    try:\n",
    "        model.diffusion.diffusion.sigma_data = float(sigma_data)\n",
    "    except (TypeError, ValueError):\n",
    "        pass\n",
    "\n",
    "files = [f for f in os.listdir(checkpoint_dir) if f.startswith('epoch_2nd') and f.endswith('.pth')]\n",
    "if not files:\n",
    "    raise FileNotFoundError(f\"No 2nd stage checkpoints found in {checkpoint_dir}\")\n",
    "sorted_files = sorted(files, key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "\n",
    "model_path = os.path.join(checkpoint_dir, sorted_files[-1])\n",
    "print(\"Loading model\", model_path)\n",
    "params_whole = torch.load(model_path, map_location='cpu', weights_only=False)\n",
    "params = params_whole.get('net', params_whole)\n",
    "\n",
    "if 'phoneme_dictionary' in params_whole:\n",
    "    ckpt_dict = params_whole['phoneme_dictionary']\n",
    "    ckpt_cfg = params_whole.get('phoneme_dictionary_config', dictionary_settings)\n",
    "    textcleaner = TextCleaner(ckpt_dict, ckpt_cfg)\n",
    "\n",
    "for key in model:\n",
    "    if key in params:\n",
    "        print('%s loaded' % key)\n",
    "        try:\n",
    "            model[key].load_state_dict(params[key])\n",
    "        except:\n",
    "            from collections import OrderedDict\n",
    "            state_dict = params[key]\n",
    "            new_state_dict = OrderedDict()\n",
    "            for k, v in state_dict.items():\n",
    "                name = k[7:] # remove `module.`\n",
    "                new_state_dict[name] = v\n",
    "            # load params\n",
    "            model[key].load_state_dict(new_state_dict, strict=False)\n",
    "#             except:\n",
    "#                 _load(params[key], model[key])\n",
    "_ = [model[key].eval() for key in model]\n",
    "if 'sigma_data' in params_whole:\n",
    "    try:\n",
    "        model.diffusion.diffusion.sigma_data = float(params_whole['sigma_data'])\n",
    "    except (TypeError, ValueError):\n",
    "        pass\n",
    "\n",
    "from Modules.diffusion.sampler import DiffusionSampler, ADPM2Sampler, KarrasSchedule\n",
    "\n",
    "sampler = DiffusionSampler(\n",
    "    model.diffusion.diffusion,\n",
    "    sampler=ADPM2Sampler(),\n",
    "    sigma_schedule=KarrasSchedule(sigma_min=0.0001, sigma_max=3.0, rho=9.0), # empirical parameters\n",
    "    clamp=False\n",
    ")\n",
    "\n",
    "def inference(text, noise, diffusion_steps=5, embedding_scale=1):\n",
    "    text = text.strip()\n",
    "    text = text.replace('\"', '')\n",
    "    ps = global_phonemizer.phonemize([text])\n",
    "    ps = word_tokenize(ps[0])\n",
    "    ps = ' '.join(ps)\n",
    "\n",
    "    tokens = textcleaner(ps)\n",
    "    tokens.insert(0, 0)\n",
    "    tokens = torch.LongTensor(tokens).to(device).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_lengths = torch.LongTensor([tokens.shape[-1]]).to(tokens.device)\n",
    "        text_mask = length_to_mask(input_lengths).to(tokens.device)\n",
    "\n",
    "        t_en = model.text_encoder(tokens, input_lengths, text_mask)\n",
    "        bert_dur = model.bert(tokens, attention_mask=(~text_mask).int())\n",
    "        d_en = model.bert_encoder(bert_dur).transpose(-1, -2)\n",
    "\n",
    "        s_pred = sampler(noise,\n",
    "              embedding=bert_dur[0].unsqueeze(0), num_steps=diffusion_steps,\n",
    "              embedding_scale=embedding_scale).squeeze(0)\n",
    "\n",
    "        s = s_pred[:, 128:]\n",
    "        ref = s_pred[:, :128]\n",
    "\n",
    "        d = model.predictor.text_encoder(d_en, s, input_lengths, text_mask)\n",
    "\n",
    "        x, _ = model.predictor.lstm(d)\n",
    "        duration = model.predictor.duration_proj(x)\n",
    "        duration = torch.sigmoid(duration).sum(axis=-1)\n",
    "        pred_dur = torch.round(duration.squeeze()).clamp(min=1)\n",
    "\n",
    "        pred_dur[-1] += 5\n",
    "\n",
    "        pred_aln_trg = torch.zeros(input_lengths, int(pred_dur.sum().data))\n",
    "        c_frame = 0\n",
    "        for i in range(pred_aln_trg.size(0)):\n",
    "            pred_aln_trg[i, c_frame:c_frame + int(pred_dur[i].data)] = 1\n",
    "            c_frame += int(pred_dur[i].data)\n",
    "\n",
    "        # encode prosody\n",
    "        en = (d.transpose(-1, -2) @ pred_aln_trg.unsqueeze(0).to(device))\n",
    "        F0_pred, N_pred = model.predictor.F0Ntrain(en, s)\n",
    "        out = model.decoder((t_en @ pred_aln_trg.unsqueeze(0).to(device)),\n",
    "                                F0_pred, N_pred, ref.squeeze().unsqueeze(0))\n",
    "\n",
    "    return out.squeeze().cpu().numpy()\n",
    "\n",
    "\n",
    "def inference_100ms(\n",
    "        text: str,\n",
    "        noise,\n",
    "        *,\n",
    "        diffusion_steps: int = 5,\n",
    "        embedding_scale: float = 1.0,\n",
    "        sample_rate: int = 24000,\n",
    "        trim_ms: int = 100,\n",
    "        remove_pause: bool = True,\n",
    "):\n",
    "    \"\"\"Standard StyleTTS2 inference with built-in tail-trim & pause removal.\n",
    "\n",
    "    Differences from the original reference:\n",
    "      \u2022 *No* extra pause phonemes/punctuation when ``remove_pause`` is *True*.\n",
    "      \u2022 Last ``trim_ms``\u2009ms of audio are discarded to remove trailing artifacts.\n",
    "      \u2022 Keeps the original behaviour of adding +5 frames to the final token\u2019s\n",
    "        predicted duration.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) TEXT PRE-PROCESS\n",
    "    text = text.strip().replace('\"', '')\n",
    "    if remove_pause:\n",
    "        text = re.sub(r\"[.,;:!?]\", \"\", text)\n",
    "\n",
    "    ps = global_phonemizer.phonemize([text])\n",
    "    phonemes = word_tokenize(ps[0])\n",
    "    if remove_pause:\n",
    "        phonemes = [p for p in phonemes if p.lower() not in (\"sp\", \"sil\", \"pau\")]\n",
    "    ps = \" \".join(phonemes)\n",
    "\n",
    "    tokens = textcleaner(ps)\n",
    "    tokens.insert(0, 0)\n",
    "    tokens = torch.LongTensor(tokens).to(device).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_lengths = torch.LongTensor([tokens.shape[-1]]).to(tokens.device)\n",
    "        text_mask = length_to_mask(input_lengths).to(tokens.device)\n",
    "\n",
    "        t_en = model.text_encoder(tokens, input_lengths, text_mask)\n",
    "        bert_dur = model.bert(tokens, attention_mask=(~text_mask).int())\n",
    "        d_en = model.bert_encoder(bert_dur).transpose(-1, -2)\n",
    "\n",
    "        s_pred = sampler(\n",
    "            noise,\n",
    "            embedding=bert_dur[0].unsqueeze(0),\n",
    "            num_steps=diffusion_steps,\n",
    "            embedding_scale=embedding_scale,\n",
    "        ).squeeze(0)\n",
    "\n",
    "        s, ref = s_pred[:, 128:], s_pred[:, :128]\n",
    "\n",
    "        d = model.predictor.text_encoder(d_en, s, input_lengths, text_mask)\n",
    "        x, _ = model.predictor.lstm(d)\n",
    "        duration = torch.sigmoid(model.predictor.duration_proj(x)).sum(axis=-1)\n",
    "        pred_dur = torch.round(duration.squeeze()).clamp(min=1)\n",
    "\n",
    "        # preserve original tweak: lengthen final token a bit\n",
    "        pred_dur[-1] += 5\n",
    "\n",
    "        pred_aln_trg = torch.zeros(input_lengths, int(pred_dur.sum().data))\n",
    "        c_frame = 0\n",
    "        for i in range(pred_aln_trg.size(0)):\n",
    "            span = int(pred_dur[i])\n",
    "            pred_aln_trg[i, c_frame:c_frame + span] = 1\n",
    "            c_frame += span\n",
    "\n",
    "        en = d.transpose(-1, -2) @ pred_aln_trg.unsqueeze(0).to(device)\n",
    "        F0_pred, N_pred = model.predictor.F0Ntrain(en, s)\n",
    "        wav = model.decoder(\n",
    "            t_en @ pred_aln_trg.unsqueeze(0).to(device),\n",
    "            F0_pred,\n",
    "            N_pred,\n",
    "            ref.squeeze().unsqueeze(0),\n",
    "        )\n",
    "\n",
    "    # 5) POST-PROCESS \u2013 trim tail\n",
    "    audio = wav.squeeze().cpu().numpy()\n",
    "    samples_trim = int(sample_rate * trim_ms / 1000)\n",
    "    if audio.shape[-1] > samples_trim:\n",
    "        audio = audio[:-samples_trim]\n",
    "\n",
    "    return audio\n",
    "\n",
    "\n",
    "def LFinference(text, s_prev, noise, alpha=0.7, diffusion_steps=5, embedding_scale=1):\n",
    "  text = text.strip()\n",
    "  text = text.replace('\"', '')\n",
    "  ps = global_phonemizer.phonemize([text])\n",
    "  ps = word_tokenize(ps[0])\n",
    "  ps = ' '.join(ps)\n",
    "\n",
    "  tokens = textcleaner(ps)\n",
    "  tokens.insert(0, 0)\n",
    "  tokens = torch.LongTensor(tokens).to(device).unsqueeze(0)\n",
    "\n",
    "  with torch.no_grad():\n",
    "      input_lengths = torch.LongTensor([tokens.shape[-1]]).to(tokens.device)\n",
    "      text_mask = length_to_mask(input_lengths).to(tokens.device)\n",
    "\n",
    "      t_en = model.text_encoder(tokens, input_lengths, text_mask)\n",
    "      bert_dur = model.bert(tokens, attention_mask=(~text_mask).int())\n",
    "      d_en = model.bert_encoder(bert_dur).transpose(-1, -2)\n",
    "\n",
    "      s_pred = sampler(noise,\n",
    "            embedding=bert_dur[0].unsqueeze(0), num_steps=diffusion_steps,\n",
    "            embedding_scale=embedding_scale).squeeze(0)\n",
    "\n",
    "      if s_prev is not None:\n",
    "          # convex combination of previous and current style\n",
    "          s_pred = alpha * s_prev + (1 - alpha) * s_pred\n",
    "\n",
    "      s = s_pred[:, 128:]\n",
    "      ref = s_pred[:, :128]\n",
    "\n",
    "      d = model.predictor.text_encoder(d_en, s, input_lengths, text_mask)\n",
    "\n",
    "      x, _ = model.predictor.lstm(d)\n",
    "      duration = model.predictor.duration_proj(x)\n",
    "      duration = torch.sigmoid(duration).sum(axis=-1)\n",
    "      pred_dur = torch.round(duration.squeeze()).clamp(min=1)\n",
    "\n",
    "      pred_aln_trg = torch.zeros(input_lengths, int(pred_dur.sum().data))\n",
    "      c_frame = 0\n",
    "      for i in range(pred_aln_trg.size(0)):\n",
    "          pred_aln_trg[i, c_frame:c_frame + int(pred_dur[i].data)] = 1\n",
    "          c_frame += int(pred_dur[i].data)\n",
    "\n",
    "      # encode prosody\n",
    "      en = (d.transpose(-1, -2) @ pred_aln_trg.unsqueeze(0).to(device))\n",
    "      F0_pred, N_pred = model.predictor.F0Ntrain(en, s)\n",
    "      out = model.decoder((t_en @ pred_aln_trg.unsqueeze(0).to(device)),\n",
    "                              F0_pred, N_pred, ref.squeeze().unsqueeze(0))\n",
    "\n",
    "  return out.squeeze().cpu().numpy(), s_pred\n",
    "\n",
    "\n",
    "def _trim_tail_if_voiceless(audio, sample_rate, trim_ms=100, voice_threshold=0.02):\n",
    "    samples_trim = int(sample_rate * trim_ms / 1000)\n",
    "    if samples_trim <= 0 or len(audio) <= samples_trim:\n",
    "        return audio\n",
    "    tail = audio[-samples_trim:]\n",
    "    energy = np.abs(tail)\n",
    "    # check if any voiced part (above threshold) is in last 100ms\n",
    "    if np.any(energy > voice_threshold):\n",
    "        return audio  # do NOT trim if voiced segment exists in tail\n",
    "    return audio[:-samples_trim]\n",
    "\n",
    "def _crossfade_concat(wavs, crossfade_ms=50, sample_rate=24000):\n",
    "    if not wavs:\n",
    "        return np.array([])\n",
    "    if len(wavs) == 1:\n",
    "        return wavs[0]\n",
    "\n",
    "    crossfade_samples = int(sample_rate * crossfade_ms / 1000)\n",
    "    result = wavs[0]\n",
    "\n",
    "    for w in wavs[1:]:\n",
    "        if len(result) > crossfade_samples and len(w) > crossfade_samples:\n",
    "            fade_out = np.linspace(1, 0, crossfade_samples)\n",
    "            fade_in = np.linspace(0, 1, crossfade_samples)\n",
    "            overlap = result[-crossfade_samples:] * fade_out + w[:crossfade_samples] * fade_in\n",
    "            result = np.concatenate([result[:-crossfade_samples], overlap, w[crossfade_samples:]])\n",
    "        else:\n",
    "            result = np.concatenate([result, w])\n",
    "\n",
    "    return result\n",
    "    \n",
    "def _append_silence(audio, sample_rate, silence_ms=200, energy_threshold=0.003):\n",
    "    silence_len = int(sample_rate * silence_ms / 1000)\n",
    "    tail = audio[-silence_len:]\n",
    "    if np.max(np.abs(tail)) < energy_threshold:\n",
    "        noise_segment = tail\n",
    "    else:\n",
    "        # Extract low-energy segments for noise reference\n",
    "        noise_segment = _estimate_noise(audio, sample_rate, segment_ms=silence_ms, energy_threshold=energy_threshold)\n",
    "        if noise_segment is None:\n",
    "            noise_segment = np.zeros(silence_len, dtype=audio.dtype)\n",
    "\n",
    "    # Repeat noise segment until desired length is reached\n",
    "    repeat_count = int(np.ceil(silence_len / len(noise_segment)))\n",
    "    extended_noise = np.tile(noise_segment, repeat_count)[:silence_len]\n",
    "    return np.concatenate([audio, extended_noise])\n",
    "\n",
    "def _estimate_noise(audio, sample_rate, segment_ms=200, energy_threshold=0.02):\n",
    "    segment_len = int(sample_rate * segment_ms / 1000)\n",
    "    noise_segments = []\n",
    "    for start in range(0, len(audio), segment_len):\n",
    "        end = start + segment_len\n",
    "        seg = audio[start:end]\n",
    "        if len(seg) < segment_len:\n",
    "            break\n",
    "        if np.max(np.abs(seg)) < energy_threshold:\n",
    "            noise_segments.append(seg)\n",
    "    if not noise_segments:\n",
    "        return None\n",
    "    return np.concatenate(noise_segments)\n",
    "\n",
    "def _denoise_audio(audio, noise_reference, reduction=0.6):\n",
    "    if noise_reference is None or len(noise_reference) == 0:\n",
    "        return audio\n",
    "    return nr.reduce_noise(y=audio, y_noise=noise_reference, sr=24000, prop_decrease=reduction)\n",
    "\n",
    "def LFinference_trim_100ms(\n",
    "        text: str,\n",
    "        s_prev=None,\n",
    "        noise=None,\n",
    "        *,\n",
    "        alpha: float = 0.7,\n",
    "        diffusion_steps: int = 5,\n",
    "        embedding_scale: float = 1.0,\n",
    "        sample_rate: int = 24000,\n",
    "        trim_ms: int = 100,\n",
    "        remove_pause: bool = True,\n",
    "        end_silence_ms: int = 200,\n",
    "        noise_reduction_threshold: float = 0.6,\n",
    "        noise_estimage_energy_threshold: float = 0.02,\n",
    "        append_silence_energy_threshold: float = 0.003\n",
    "):\n",
    "    text = text.strip().replace('\"', '')\n",
    "    #if remove_pause:\n",
    "        #text = re.sub(r\"[.,;:!?]\", \"\", text)\n",
    "\n",
    "    ps = global_phonemizer.phonemize([text])\n",
    "    phonemes = word_tokenize(ps[0])\n",
    "    if remove_pause:\n",
    "        phonemes = [p for p in phonemes if p.lower() not in (\"sp\", \"sil\", \"pau\")]\n",
    "    ps = \" \".join(phonemes)\n",
    "\n",
    "    tokens = textcleaner(ps)\n",
    "    tokens.insert(0, 0)\n",
    "    tokens = torch.LongTensor(tokens).to(device).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_lengths = torch.LongTensor([tokens.shape[-1]]).to(tokens.device)\n",
    "        text_mask = length_to_mask(input_lengths).to(tokens.device)\n",
    "\n",
    "        t_en = model.text_encoder(tokens, input_lengths, text_mask)\n",
    "        bert_dur = model.bert(tokens, attention_mask=(~text_mask).int())\n",
    "        d_en = model.bert_encoder(bert_dur).transpose(-1, -2)\n",
    "\n",
    "        s_pred = sampler(\n",
    "            noise,\n",
    "            embedding=bert_dur[0].unsqueeze(0),\n",
    "            num_steps=diffusion_steps,\n",
    "            embedding_scale=embedding_scale,\n",
    "        ).squeeze(0)\n",
    "\n",
    "        if s_prev is not None:\n",
    "            s_pred = alpha * s_prev + (1.0 - alpha) * s_pred\n",
    "\n",
    "        s, ref = s_pred[:, 128:], s_pred[:, :128]\n",
    "        d = model.predictor.text_encoder(d_en, s, input_lengths, text_mask)\n",
    "        x, _ = model.predictor.lstm(d)\n",
    "        duration = torch.sigmoid(model.predictor.duration_proj(x)).sum(axis=-1)\n",
    "        pred_dur = torch.round(duration.squeeze()).clamp(min=1)\n",
    "\n",
    "        pred_aln_trg = torch.zeros(input_lengths, int(pred_dur.sum().data))\n",
    "        c = 0\n",
    "        for i in range(pred_aln_trg.size(0)):\n",
    "            span = int(pred_dur[i])\n",
    "            pred_aln_trg[i, c:c + span] = 1\n",
    "            c += span\n",
    "\n",
    "        en = d.transpose(-1, -2) @ pred_aln_trg.unsqueeze(0).to(device)\n",
    "        F0_pred, N_pred = model.predictor.F0Ntrain(en, s)\n",
    "        wav = model.decoder(\n",
    "            t_en @ pred_aln_trg.unsqueeze(0).to(device),\n",
    "            F0_pred,\n",
    "            N_pred,\n",
    "            ref.squeeze().unsqueeze(0),\n",
    "        )\n",
    "\n",
    "    audio = wav.squeeze().cpu().numpy()\n",
    "    noise_ref = _estimate_noise(audio, sample_rate, energy_threshold=noise_estimage_energy_threshold)\n",
    "    audio = _denoise_audio(audio, noise_ref, reduction=noise_reduction_threshold)\n",
    "    audio = _trim_tail_if_voiceless(audio, sample_rate, trim_ms)\n",
    "    audio = _append_silence(audio, sample_rate, end_silence_ms, energy_threshold=append_silence_energy_threshold)\n",
    "    return audio, s_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vuCbS0gdArgJ"
   },
   "source": [
    "### Synthesize speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Ud1Y-kbBPTw"
   },
   "outputs": [],
   "source": [
    "# @title Input Text { display-mode: \"form\" }\n",
    "# synthesize a text\n",
    "#text = \"StyleTTS 2 is a text-to-speech model that leverages style diffusion and adversarial training with large speech language models to achieve human-level text-to-speech synthesis.\" # @param {type:\"string\"}\n",
    "#text = \"P\u0159\u00edb\u011bh str\u00fd\u010dka Martina je jin\u00e1 kniha, ne\u017e na jak\u00e9 jste zvykl\u00ed. A dost mo\u017en\u00e1 to ani nen\u00ed kniha pro v\u00e1s. Proto tak\u00e9 vych\u00e1z\u00ed v mal\u00e9m n\u00e1kladu, jen pro \u00fazk\u00fd okruh lid\u00ed. Nen\u00ed to ani historick\u00e1 beletrie, ani fantazy, ani soudob\u00e1 pr\u00f3za. Nejbl\u00ed\u017ee m\u00e1 k inicia\u010dn\u00edmu rom\u00e1nu.\"\n",
    "#text = \"T\u0159i roky psan\u00e1 kniha, kterou nen\u00ed lehk\u00e9 za\u0159adit. V prv\u00e9 f\u00e1zi den\u00ed\u010dek studentky, kter\u00e1 hled\u00e1 sv\u00e9ho str\u00fd\u010dka. V druh\u00e9 f\u00e1zi vidiny, st\u00edny minulosti. Dechberouc\u00ed obrazy bitev, zk\u00e1zy, rozcest\u00ed \u010desk\u00e9 a evropsk\u00e9 minulosti. To je P\u0159\u00edb\u011bh str\u00fd\u010dka Martina.\"\n",
    "#text = \"Historick\u00e1 rovina knihy se pohybuje kolem roku 950, v dob\u011b boje kn\u00ed\u017eete Boleslava s n\u011bmeck\u00fdm kr\u00e1lem Otou. Historick\u00fd p\u0159\u00edb\u011bh vlastn\u011b za\u010d\u00edn\u00e1 smrt\u00ed hlavn\u00edho hrdiny, \u0161\u00e9f\u0161picla a \u0161ed\u00e9 eminence \u010desk\u00e9 zem\u011b Martina z Wartberka a ztracen\u00fdm zemsk\u00fdm tributem, kter\u00fd m\u011bl konvoj dov\u00e9st k \u0159\u00ed\u0161sk\u00e9mu kr\u00e1li.\"\n",
    "#text = \"Hore\u010dnou snahou zajistit zemi, kter\u00e1 se najednou ocitla ve smrteln\u00e9m ohro\u017een\u00ed, proto\u017ee kdo v\u00ed, co v\u0161echno se ztratilo s Wartberkovou smrt\u00ed.\"\n",
    "#text = \"Sou\u010dasn\u00fd p\u0159\u00edb\u011bh je hled\u00e1n\u00ed Veroniky po str\u00fd\u010dkovi, kter\u00fd se ztratil. Kam a jak, to vlastn\u011b nikdo nev\u00ed. A\u017e te\u010f za\u010d\u00edn\u00e1 Veronika nach\u00e1zet spojnice mezi sv\u00fdmi vizemi a sny se sou\u010dasnost\u00ed. A uv\u011bdomuje si, \u017ee Martin historick\u00fd je t\u00edm Martinem sou\u010dasn\u00fdm, \u017ee naj\u00edt jednoho znamen\u00e1 naj\u00edt druh\u00e9ho. K\u00e9\u017e by to bylo tak jednoduch\u00e9.\"\n",
    "#text = \"Jen\u017ee, darmo se ne\u0159\u00edk\u00e1, \u017ee cesta je c\u00edl. Plat\u00ed to i v tomto p\u0159\u00edpad\u011b - proj\u00edt cestu je podstatn\u00e9.\"\n",
    "#text = \"V knize se potk\u00e1te se dv\u011bmi historick\u00fdmi bitvami, kter\u00e9 dnes u\u017e vlastn\u011b upadly v zapomn\u011bn\u00ed.\"\n",
    "#text = \"Bitvou u Lechu v roce 955, kde padl prakticky cel\u00fd \u010desk\u00fd vojensk\u00fd sbor v boji proti Ma\u010far\u016fm - zdarma se dozv\u00edte, z \u010deho je jm\u00e9no \"\"ma\u010fa\u0159i\"\" odvozeno - a s bitvou u Nov\u00e9ho hradu v roce 950, kde - a o tom kroniky cudn\u011b ml\u010d\u00ed - porazil kn\u00ed\u017ee Boleslav kr\u00e1le Otu a u\u010dinil z \u010cech plnopr\u00e1vn\u00e9ho souseda a souputn\u00edka \u0158\u00ed\u0161e.\"\n",
    "#text = \"Setk\u00e1te se tu s \u0159adou historick\u00fdch postav. Vlastn\u011b v\u0161echny postavy v knize jsou postavy \u017eij\u00edc\u00ed, historick\u00e9, kter\u00e9 maj\u00ed n\u011bjak\u00fd sv\u016fj p\u0159edobraz. V\u00fdjimkou je Maxmili\u00e1n ze Schweringenu, komo\u0159\u00ed Oty. D\u016fvod? Toho skute\u010dn\u00e9ho nem\u00e1m r\u00e1d a tak jsem ho necht\u011bl ani zmi\u0148ovat. Snad mi prominete.\"\n",
    "#text = \"\u0625\u0630\u0627 \u0643\u0627\u0646 \u0647\u0646\u0627\u0643 \u064a\u0648\u0645 \u0639\u0645\u0644 \u0648\u0627\u062d\u062f \u0641\u0642\u0637 \u0628\u064a\u0646 \u0639\u0637\u0644\u062a\u064a\u0646 \u0631\u0633\u0645\u064a\u062a\u064a\u0646\u060c \u064a\u0639\u062a\u0628\u0631 \u0647\u0630\u0627 \u0627\u0644\u064a\u0648\u0645 \u062c\u0632\u0621\u0627 \u0645\u0646 \u0627\u0644\u0639\u0637\u0644\u0629\"\n",
    "#text = \"\u0627\u0644\u0644\u064a \u0645\u0627 \u064a\u0639\u0631\u0641 \u0627\u0644\u0635\u0642\u0631 \u064a\u0634\u0648\u064a\u0647 \u0648 \u0645\u0646 \u0637\u0648\u0644 \u0627\u0644\u063a\u064a\u0628\u0627\u062a \u062c\u0627\u0628 \u0627\u0644\u063a\u0646\u0627\u064a\u0645\"\n",
    "#text = '\"Um\u00ed\u0161 to p\u0159elo\u017eit?\" Zeptal se m\u011b.\"'\n",
    "#text = '\"Petra je latinsky sk\u00e1la, ale z\u00e1rove\u0148 je to jm\u00e9no - Petr. Je odvozen\u00e9 ze slova sk\u00e1la, \u017ee?\" Zeptal se Martin.'\n",
    "#text = 'A pak mi to do\u0161lo. Tak\u017ee se ned\u00e1 \u0159\u00edct, jestli Je\u017e\u00ed\u0161 mluv\u00ed o\u00a0Petrovi nebo o\u00a0sk\u00e1le?'\n",
    "#text = '\u0627\u0643\u062a\u0634\u0641 \u0628\u0639\u062f \u0641\u062a\u0631\u0647 \u0637\u0648\u064a\u0644\u0647 \u0645\u0627\u0641\u064a \u0634\u064a \u0641\u064a \u0627\u0644\u062d\u064a\u0627\u0629 \u063a\u0644\u0637 \u0627\u0648 \u0643\u0630\u0628 \u0627\u0648 \u0644\u064a\u0633 \u0635\u062d\u064a\u062d \u0644\u0623 \u0647\u0646\u0627\u0643 \u0648\u062c\u0647\u0627\u062a \u0646\u0638\u0631 \u0645\u062e\u062a\u0644\u0641\u0647 \u0627\u0646\u062a \u062a\u0624\u0645\u0646 \u0628\u0647\u0630\u0627 \u0627\u0644\u0634\u064a'\n",
    "#text = '\u0648\u062a\u0637\u0631\u0642 \u0627\u0644\u062c\u0627\u0646\u0628\u0627\u0646 \u0625\u0644\u0649 \u062a\u0637\u0648\u0631\u0627\u062a \u0627\u0644\u0645\u0644\u0641 \u0627\u0644\u0633\u0648\u0631\u064a\u060c \u0648\u0623\u0643\u062f\u0627 \u0623\u0647\u0645\u064a\u0629 \u0627\u0644\u062a\u0632\u0627\u0645 \u0627\u0644\u0645\u062c\u062a\u0645\u0639 \u0627\u0644\u062f\u0648\u0644\u064a \u0628\u0627\u0644\u0645\u0639\u0627\u0647\u062f\u0627\u062a \u0648\u0627\u0644\u0627\u062a\u0641\u0627\u0642\u064a\u0627\u062a \u0627\u0644\u062f\u0648\u0644\u064a\u0629 \u0630\u0627\u062a \u0627\u0644\u0635\u0644\u0629\u060c \u0643\u0645\u0627 \u0634\u062f\u062f\u0627 \u0639\u0644\u0649 \u062f\u0648\u0631 \u0627\u0644\u0645\u0646\u0638\u0645\u0629 \u0641\u064a \u0636\u0645\u0627\u0646 \u0627\u0644\u062a\u0646\u0641\u064a\u0630 \u0627\u0644\u0641\u0639\u0651\u0627\u0644 \u0644\u0627\u062a\u0641\u0627\u0642\u064a\u0629 \u062d\u0638\u0631 \u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0627\u0644\u0623\u0633\u0644\u062d\u0629 \u0627\u0644\u0643\u064a\u0645\u064a\u0627\u0626\u064a\u0629.'\n",
    "#text = '\u0648\u0623\u0634\u0627\u062f \u0633\u0639\u0627\u062f\u0629 \u0627\u0644\u0645\u062f\u064a\u0631 \u0627\u0644\u0639\u0627\u0645 \u0644\u0645\u0646\u0638\u0645\u0629 \u062d\u0638\u0631 \u0627\u0644\u0623\u0633\u0644\u062d\u0629 \u0627\u0644\u0643\u064a\u0645\u064a\u0627\u0626\u064a\u0629\u060c \u062e\u0644\u0627\u0644 \u0627\u0644\u0627\u062c\u062a\u0645\u0627\u0639\u060c \u0628\u062f\u0648\u0631 \u062f\u0648\u0644\u0629 \u0642\u0637\u0631 \u0641\u064a \u062a\u0645\u062b\u064a\u0644 \u0645\u0635\u0627\u0644\u062d \u0627\u0644\u062c\u0645\u0647\u0648\u0631\u064a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629 \u0627\u0644\u0633\u0648\u0631\u064a\u0629 \u0641\u064a \u0627\u0644\u0645\u0646\u0638\u0645\u0629\u060c  \u0648\u062f\u0639\u0645\u0647\u0627 \u0644\u0644\u062c\u0647\u0648\u062f \u0627\u0644\u062f\u0648\u0644\u064a\u0629 \u0627\u0644\u0631\u0627\u0645\u064a\u0629 \u0625\u0644\u0649 \u062a\u062d\u0642\u064a\u0642 \u0627\u0644\u0623\u0645\u0646 \u0648\u0627\u0644\u0627\u0633\u062a\u0642\u0631\u0627\u0631 \u0639\u0644\u0649 \u0627\u0644\u0645\u0633\u062a\u0648\u064a\u064a\u0646 \u0627\u0644\u0625\u0642\u0644\u064a\u0645\u064a \u0648\u0627\u0644\u062f\u0648\u0644\u064a\u060c \u0648\u0627\u0644\u062a\u0632\u0627\u0645\u0647\u0627 \u0628\u0645\u0628\u0627\u062f\u0626 \u0627\u0644\u0642\u0627\u0646\u0648\u0646 \u0627\u0644\u062f\u0648\u0644\u064a'\n",
    "text = '\u0623\u064e\u0644\u0650\u0641 \u0628\u0627 \u062a\u0627 \u062b\u0627 \u062c\u0650\u064a\u0645 \u062d\u064e\u0627 \u062e\u064e\u0627 \u062f\u064e\u0627\u0644 \u0630\u064e\u0627\u0644 \u0631\u0627 \u0632\u064e\u0627\u064a \u0633\u0650\u064a\u0646 \u0634\u0650\u064a\u0646 \u0635\u064e\u0627\u062f \u0636\u064e\u0627\u062f \u0637\u064e\u0627 \u0638\u064e\u0627 \u0639\u064e\u064a\u0646 \u063a\u064e\u064a\u0646 \u0641\u064e\u0627 \u0642\u064e\u0627\u0641 \u0643\u064e\u0627\u0641 \u0644\u064e\u0627\u0645 \u0645\u0650\u064a\u0645 \u0646\u064f\u0648\u0646 \u0647\u064e\u0627 \u0648\u064e\u0627\u0648 \u064a\u064e\u0627'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TM2NjuM7B6sz"
   },
   "source": [
    "#### Basic synthesis (5 diffusion steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KILqC-V-Ay5e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#torch.manual_seed(17484051992422920962)\n",
    "#print(\"seed\", torch.initial_seed())\n",
    "print(\"seed\", torch.seed())\n",
    "start = time.time()\n",
    "noise = torch.randn(1,1,256).to(device)\n",
    "wav = inference(text, noise, diffusion_steps=10, embedding_scale=1)\n",
    "rtf = (time.time() - start) / (len(wav) / 24000)\n",
    "print(f\"RTF = {rtf:5f}\")\n",
    "display(ipd.Audio(wav, rate=24000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZk9o-EzCBVx"
   },
   "source": [
    "#### With higher diffusion steps (more diverse)\n",
    "Since the sampler is ancestral, the higher the stpes, the more diverse the samples are, with the cost of slower synthesis speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9_OHtzMbB9gL"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "noise = torch.randn(1,1,256).to(device)\n",
    "wav = inference(text, noise, diffusion_steps=10, embedding_scale=1)\n",
    "rtf = (time.time() - start) / (len(wav) / 24000)\n",
    "print(f\"RTF = {rtf:5f}\")\n",
    "import IPython.display as ipd\n",
    "display(ipd.Audio(wav, rate=24000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyDACd-0CaqL"
   },
   "source": [
    "### Speech expressiveness\n",
    "The following section recreates the samples shown in [Section 6](https://styletts2.github.io/#emo) of the demo page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRkS5VWxCck4"
   },
   "source": [
    "#### With embedding_scale=1\n",
    "This is the classifier-free guidance scale. The higher the scale, the more conditional the style is to the input text and hence more emotional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H5g5RO-mCbZB"
   },
   "outputs": [],
   "source": [
    "texts = {}\n",
    "texts['Happy'] = \"We are happy to invite you to join us on a journey to the past, where we will visit the most amazing monuments ever built by human hands.\"\n",
    "texts['Sad'] = \"I am sorry to say that we have suffered a severe setback in our efforts to restore prosperity and confidence.\"\n",
    "texts['Angry'] = \"The field of astronomy is a joke! Its theories are based on flawed observations and biased interpretations!\"\n",
    "texts['Surprised'] = \"I can't believe it! You mean to tell me that you have discovered a new species of bacteria in this pond?\"\n",
    "\n",
    "for k,v in texts.items():\n",
    "    noise = torch.randn(1,1,256).to(device)\n",
    "    wav = inference(v, noise, diffusion_steps=10, embedding_scale=1)\n",
    "    print(k + \": \")\n",
    "    display(ipd.Audio(wav, rate=24000, normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4S8TXSpCgpA"
   },
   "source": [
    "#### With embedding_scale=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xHHIdeNrCezC"
   },
   "outputs": [],
   "source": [
    "texts = {}\n",
    "texts['Happy'] = \"We are happy to invite you to join us on a journey to the past, where we will visit the most amazing monuments ever built by human hands.\"\n",
    "texts['Sad'] = \"I am sorry to say that we have suffered a severe setback in our efforts to restore prosperity and confidence.\"\n",
    "texts['Angry'] = \"The field of astronomy is a joke! Its theories are based on flawed observations and biased interpretations!\"\n",
    "texts['Surprised'] = \"I can't believe it! You mean to tell me that you have discovered a new species of bacteria in this pond?\"\n",
    "\n",
    "for k,v in texts.items():\n",
    "    noise = torch.randn(1,1,256).to(device)\n",
    "    wav = inference(v, noise, diffusion_steps=10, embedding_scale=2) # embedding_scale=2 for more pronounced emotion\n",
    "    print(k + \": \")\n",
    "    display(ipd.Audio(wav, rate=24000, normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAh7Tov4CkuH"
   },
   "source": [
    "### Long-form generation\n",
    "This section includes basic implementation of Algorithm 1 in the paper for consistent longform audio generation. The example passage is taken from [Section 5](https://styletts2.github.io/#long) of the demo page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "IJwUbgvACoDu"
   },
   "outputs": [],
   "source": [
    "passage = '''\n",
    "P\u0159\u00edb\u011bh str\u00fd\u010dka Martina je jin\u00e1 kniha, ne\u017e na jak\u00e9 jste zvykl\u00ed.\n",
    "A dost mo\u017en\u00e1 to ani nen\u00ed kniha pro v\u00e1s.\n",
    "Proto tak\u00e9 vych\u00e1z\u00ed v mal\u00e9m n\u00e1kladu, jen pro \u00fazk\u00fd okruh lid\u00ed.\n",
    "Nen\u00ed to ani historick\u00e1 beletrie, ani fantazy, ani soudob\u00e1 pr\u00f3za.\n",
    "Nejbl\u00ed\u017ee m\u00e1 k inicia\u010dn\u00edmu rom\u00e1nu.\n",
    "Kniha st\u0159\u00edd\u00e1 neum\u011bl\u00e9 vypr\u00e1v\u011bn\u00ed studenty a barvit\u00e9 sny, vize.\n",
    "Budete si st\u011b\u017eovat, \u017ee nesn\u00e1\u0161\u00edte jej\u00ed sou\u010dasn\u00e9 \u010d\u00e1sti - nebo, \u017ee nem\u00e1te r\u00e1di ty historick\u00e9.\n",
    "Bude v\u00e1m chyb\u011bt konec nebo p\u0159eb\u00fdvat jeho mnohozna\u010dnost.\n",
    "Pak to z\u0159ejm\u011b nen\u00ed kniha pro v\u00e1s nebo pro tuto va\u0161i \u017eivotn\u00ed etapu.\n",
    "Mo\u017en\u00e1 se za\u010dtete a a\u017e odtrhnete unaven\u00e9 o\u010di o mnoho hodin pozd\u011bji, budete sv\u011bt vid\u011bt jinak, s pochybnostmi.\n",
    "T\u0159i roky psan\u00e1 kniha, kterou nen\u00ed lehk\u00e9 za\u0159adit.\n",
    "V prv\u00e9 f\u00e1zi den\u00ed\u010dek studentky, kter\u00e1 hled\u00e1 sv\u00e9ho str\u00fd\u010dka.\n",
    "V druh\u00e9 f\u00e1zi vidiny, st\u00edny minulosti.\n",
    "Dechberouc\u00ed obrazy bitev, zk\u00e1zy, rozcest\u00ed \u010desk\u00e9 a evropsk\u00e9 minulosti.\n",
    "To je P\u0159\u00edb\u011bh str\u00fd\u010dka Martina.\n",
    "Historick\u00e1 rovina knihy se pohybuje kolem roku 950, v dob\u011b boje kn\u00ed\u017eete Boleslava s n\u011bmeck\u00fdm kr\u00e1lem Otou.\n",
    "Historick\u00fd p\u0159\u00edb\u011bh vlastn\u011b za\u010d\u00edn\u00e1 smrt\u00ed hlavn\u00edho hrdiny, \u0161\u00e9f\u0161picla a \u0161ed\u00e9 eminence \u010desk\u00e9 zem\u011b Martina z Wartberka a ztracen\u00fdm zemsk\u00fdm tributem, kter\u00fd m\u011bl konvoj dov\u00e9st k \u0159\u00ed\u0161sk\u00e9mu kr\u00e1li.\n",
    "Hore\u010dnou snahou zajistit zemi, kter\u00e1 se najednou ocitla ve smrteln\u00e9m ohro\u017een\u00ed, proto\u017ee kdo v\u00ed, co v\u0161echno se ztratilo s Wartberkovou smrt\u00ed.\n",
    "Sou\u010dasn\u00fd p\u0159\u00edb\u011bh je hled\u00e1n\u00ed Veroniky po str\u00fd\u010dkovi, kter\u00fd se ztratil.\n",
    "Kam a jak, to vlastn\u011b nikdo nev\u00ed.\n",
    "A\u017e te\u010f za\u010d\u00edn\u00e1 Veronika nach\u00e1zet spojnice mezi sv\u00fdmi vizemi a sny se sou\u010dasnost\u00ed.\n",
    "A uv\u011bdomuje si, \u017ee Martin historick\u00fd je t\u00edm Martinem sou\u010dasn\u00fdm, \u017ee naj\u00edt jednoho znamen\u00e1 naj\u00edt druh\u00e9ho.\n",
    "K\u00e9\u017e by to bylo tak jednoduch\u00e9...\n",
    "Jen\u017ee, darmo se ne\u0159\u00edk\u00e1, \u017ee cesta je c\u00edl.\n",
    "Plat\u00ed to i v tomto p\u0159\u00edpad\u011b - proj\u00edt cestu je podstatn\u00e9.\n",
    "V knize se potk\u00e1te se dv\u011bmi historick\u00fdmi bitvami, kter\u00e9 dnes u\u017e vlastn\u011b upadly v zapomn\u011bn\u00ed.\n",
    "Bitvou u Lechu v roce 955, kde padl prakticky cel\u00fd \u010desk\u00fd vojensk\u00fd sbor v boji proti Ma\u010far\u016fm. Zdarma se dozv\u00edte, z \u010deho je jm\u00e9no \"ma\u010fa\u0159i\" odvozeno.\n",
    "A s bitvou u Nov\u00e9ho hradu v roce 950, kde, a o tom kroniky cudn\u011b ml\u010d\u00ed, porazil kn\u00ed\u017ee Boleslav kr\u00e1le Otu a u\u010dinil z \u010cech plnopr\u00e1vn\u00e9ho souseda a souputn\u00edka \u0158\u00ed\u0161e.\n",
    "Setk\u00e1te se tu s \u0159adou historick\u00fdch postav.\n",
    "Vlastn\u011b v\u0161echny postavy v knize jsou postavy \u017eij\u00edc\u00ed, historick\u00e9, kter\u00e9 maj\u00ed n\u011bjak\u00fd sv\u016fj p\u0159edobraz.\n",
    "V\u00fdjimkou je Maxmili\u00e1n ze Schweringenu, komo\u0159\u00ed Oty.\n",
    "D\u016fvod?\n",
    "Toho skute\u010dn\u00e9ho nem\u00e1m r\u00e1d a tak jsem ho necht\u011bl ani zmi\u0148ovat. Snad mi prominete...\n",
    "''' # @param {type:\"string\"}\n",
    "\n",
    "# passage = '''\n",
    "# Tu fotku jsem na\u0161la ve v\u00fdpravn\u00e9 fotografick\u00e9 publikaci o\u00a0Pra\u017esk\u00e9m hradu a hned, jak jsem ji vid\u011bla, jsem v\u011bd\u011bla, \u017ee tohle je to spr\u00e1vn\u00e9 m\u00edsto, sk\u00e1la.\n",
    "# Proto\u017ee abych pravdu \u0159ekla, neo\u010dek\u00e1vala jsem, \u017ee Martin by m\u011bl v\u00a0oblib\u011b sk\u00e1lu jako\u017eto p\u0159\u00edrodn\u00ed \u00fatvar.\n",
    "# V\u00a0jeho p\u0159\u00edrod\u011b je sk\u00e1la symbolem, n\u00e1znakem.\n",
    "# A sk\u00e1la v\u00a0podob\u011b p\u0159esmy\u010dky latinsk\u00e9ho petra je ide\u00e1ln\u00edm symbolem. Jsem si skoro jist\u00e1, \u017ee t\u00edm m\u00edstem sch\u016fzky je sk\u00e1la v\u00a0podob\u011b svat\u00e9ho Petra.\n",
    "# Fotografie poch\u00e1z\u00ed z\u00a0vn\u011bj\u0161\u00ed zdi kaple svat\u00e9ho K\u0159\u00ed\u017ee na druh\u00e9m n\u00e1dvo\u0159\u00ed Pra\u017esk\u00e9ho hradu a pamatuju si, jak jsme kdysi, to mi bylo n\u011bco m\u00e1lo p\u0159es deset, kolem t\u00e9 sochy \u0161li.\n",
    "# Martin mi uk\u00e1zal ten n\u00e1pis a p\u0159e\u010detl ho:\u00a0\"Tu es Petrus et super hanc petram aedificabo ecclesiam meam.\"\n",
    "# \"Um\u00ed\u0161 to p\u0159elo\u017eit?\" Zeptal se m\u011b.\n",
    "# \u0160\u00e1rka s\u00a0n\u00e1mi nebyla. Le\u017eela doma nemocn\u00e1 a vztekala se, \u017ee ji mamka nepustila.\n",
    "# Za\u010dala jsem slabikovat: \"Ty, jsi, Petr\" a pak u\u017e jsem si na ten ver\u0161 z\u00a0Bible vzpomn\u011bla a do\u0159ekla ho: \"Petr, Sk\u00e1la - a nad tou sk\u00e1lou vybuduji svoji c\u00edrkev.\"\n",
    "# \"Pamatuje\u0161 si to dob\u0159e, V\u00edt\u011bzko, ale to tam nen\u00ed.\"\n",
    "# P\u0159el\u00e9tla jsem o\u010dima ten n\u00e1pis, slovo po slov\u011b a s\u00a0drzost\u00ed desetilet\u00e9ho v\u0161ev\u011bda \u0159ekla: \"Ale je!\"\n",
    "# \"Petra je latinsky sk\u00e1la, ale z\u00e1rove\u0148 je to jm\u00e9no - Petr. Je odvozen\u00e9 ze slova sk\u00e1la, \u017ee?\" Zeptal se Martin.\n",
    "# \"Ano, to je,\" zamyslela jsem se.\n",
    "# A pak mi to do\u0161lo: \"Tak\u017ee se ned\u00e1 \u0159\u00edct, jestli Je\u017e\u00ed\u0161 mluv\u00ed o\u00a0Petrovi nebo o\u00a0sk\u00e1le?\"\n",
    "# \"To ne. Z\u00a0latinsk\u00e9ho p\u0159ekladu se to opravdu \u0159\u00edct ned\u00e1. Proto to do \u010de\u0161tiny p\u0159ekl\u00e1daj\u00ed r\u016fzn\u011b, ne ka\u017ed\u00fd p\u0159ekladatel ten dvojsmysl akceptoval nebo znal origin\u00e1l.\"\n",
    "# \"Jak ten ver\u0161 p\u0159ekl\u00e1d\u00e1 kralick\u00e1?\"\n",
    "# Zavrt\u011bla jsem hlavou, \u017ee nev\u00edm. Nem\u00e1m kralickou r\u00e1da. Rad\u0161i m\u00e1m ekumenick\u00fd p\u0159eklad, kter\u00fd je \u010dtiv\u011bj\u0161\u00ed. Obzvl\u00e1\u0161\u0165 pro desetilet\u00e9 d\u00edt\u011b.\n",
    "# '''\n",
    "passage = '''\n",
    "\u0641\u064a \u0627\u0644\u062a\u0642\u0631\u064a\u0631 \u0627\u0644\u0623\u062e\u064a\u0631 \u0639\u0646 \u062a\u0637\u0648\u0631\u0627\u062a \u0627\u0644\u0645\u0634\u0631\u0648\u0639\u060c \u0642\u064a\u0644 \u0625\u0646 \u0627\u0644\u0641\u0631\u064a\u0642 \u0633\u064a\u0642\u0648\u0645 \u0628\u0640 \u062a\u0637\u0631\u0642 \u0634\u0627\u0645\u0644 \u0644\u0643\u0644 \u0627\u0644\u062c\u0648\u0627\u0646\u0628\u060c \u0644\u0643\u0646 \u0639\u0646\u062f \u0627\u0644\u0646\u0637\u0642 \u0638\u0647\u0631\u062a \u0643\u0644\u0645\u0629 \u062a\u0637\u0631\u0642 \u0648\u0643\u0623\u0646\u0647\u0627 \u062a\u0628\u062f\u0623 \u0628\u062d\u0631\u0641 \u0627\u0644\u0637\u0627\u0621 \u0628\u062f\u0644 \u0627\u0644\u062a\u0627\u0621\u060c \u0648\u0638\u0647\u0631\u062a \u0643\u0644\u0645\u0629 \u062a\u0637\u0648\u0631\u0627\u062a \u0648\u0643\u0623\u0646\u0647\u0627 \u062a\u0628\u062f\u0623 \u0628\u062d\u0631\u0641 \u0627\u0644\u0637\u0627\u0621 \u0628\u062f\u0644\u064b\u0627 \u0645\u0646 \u0627\u0644\u062a\u0627\u0621. \u0643\u0630\u0644\u0643 \u062a\u0643\u0631\u0631 \u0627\u0644\u0623\u0645\u0631 \u0639\u0646\u062f \u0627\u0644\u062d\u062f\u064a\u062b \u0639\u0646 \u062a\u0642\u064a\u064a\u0645 \u0627\u0644\u0646\u062a\u0627\u0626\u062c\u060c \u062d\u064a\u062b \u0646\u0637\u0642\u0647\u0627 \u0627\u0644\u0646\u0638\u0627\u0645 \u062a\u0643\u064a\u0645 \u0628\u062f\u0644\u064b\u0627 \u0645\u0646 \u062a\u0642\u064a\u064a\u0645\u060c \u0645\u0645\u0627 \u062c\u0639\u0644 \u062d\u0631\u0641 \u0627\u0644\u0642\u0627\u0641 \u064a\u062a\u062d\u0648\u0644 \u0625\u0644\u0649 \u0643\u0627\u0641\u060c \u0648\u0623\u064a\u0636\u064b\u0627 \u0641\u064a \u0639\u0628\u0627\u0631\u0629 \"\u0647\u0630\u0647 \u0642\u0648\u0629 \u0625\u0636\u0627\u0641\u064a\u0629\"\u060c \u062a\u062d\u0648\u0644\u062a \u0625\u0644\u0649 \"\u0643\u0648\u0629 \u0625\u0636\u0627\u0641\u064a\u0629\". \u0623\u0645\u0627 \u0639\u0646\u062f \u0630\u0643\u0631 \u0627\u0644\u0635\u0644\u0629 \u0628\u064a\u0646 \u0627\u0644\u0623\u0642\u0633\u0627\u0645\u060c \u0641\u0642\u062f \u0642\u0644\u0628 \u0627\u0644\u0646\u0638\u0627\u0645 \u0627\u0644\u062d\u0631\u0641 \u0641\u0642\u0631\u0623\u0647\u0627 \u0627\u0644\u0633\u0644\u0629 \u0628\u062f\u0644\u064b\u0627 \u0645\u0646 \u0627\u0644\u0635\u0644\u0629\u060c \u0648\u0627\u0644\u0639\u0643\u0633 \u062d\u0635\u0644 \u0641\u064a \u0643\u0644\u0645\u0629 \u0627\u0644\u0623\u0633\u0644\u062d\u0629 \u062d\u064a\u062b \u0638\u0647\u0631\u062a \"\u0627\u0644\u0623\u0635\u0644\u062d\u0629\" \u0628\u062f\u0644\u064b\u0627 \u0645\u0646 \"\u0627\u0644\u0623\u0633\u0644\u062d\u0629\". \u0648\u0645\u0646 \u0627\u0644\u0645\u0634\u0643\u0644\u0627\u062a \u0627\u0644\u0645\u062a\u0643\u0631\u0631\u0629 \u0623\u0646 \u0643\u0644\u0645\u0629 \u0645\u0646\u0638\u0645\u0629 \u0644\u0627 \u062a\u064f\u0642\u0631\u0623 \u0643\u0645\u0627 \u064a\u0646\u0628\u063a\u064a\u060c \u0625\u0630 \u064a\u0646\u0637\u0642\u0647\u0627 TTS \u0625\u0645\u0627 \"\u0645\u0646\u0638\u0645\u0647\" \u0623\u0648 \"\u0645\u0646\u0638\u0645\u0627\u062a\"\u060c \u0641\u064a\u062e\u062a\u0641\u064a \u0627\u0644\u0641\u0631\u0642 \u0628\u064a\u0646 \u0627\u0644\u0645\u0641\u0631\u062f \u0648\u0627\u0644\u062c\u0645\u0639. \u0648\u0623\u062e\u064a\u0631\u064b\u0627 \u0641\u064a \u0627\u0644\u062e\u0637\u0629 \u0627\u0644\u062a\u0639\u0644\u064a\u0645\u064a\u0629 \u0648\u0631\u062f\u062a \u0639\u0628\u0627\u0631\u0629 \"\u0647\u0630\u0627 \u0627\u0644\u0628\u0631\u0646\u0627\u0645\u062c \u0645\u0642\u0633\u0645 \u0625\u0644\u0649 \u0627\u0644\u0645\u0633\u062a\u0648\u064a\u064a\u0646 \u0627\u0644\u0623\u0648\u0644 \u0648\u0627\u0644\u062b\u0627\u0646\u064a\"\u060c \u0644\u0643\u0646 \u0627\u0644\u0645\u062d\u0631\u0643 \u0644\u0645 \u064a\u0646\u0637\u0642 \u0643\u0644\u0645\u0629 \u0627\u0644\u0645\u0633\u062a\u0648\u064a\u064a\u0646 \u0628\u0634\u0643\u0644 \u0648\u0627\u0636\u062d\u060c \u0628\u0644 \u062c\u0639\u0644\u0647\u0627 \u0623\u062d\u064a\u0627\u0646\u064b\u0627 \"\u0627\u0644\u0645\u0633\u062a\u0648\u064a\u0627\u0646\" \u0648\u0623\u062d\u064a\u0627\u0646\u064b\u0627 \u0628\u0634\u0643\u0644 \u063a\u064a\u0631 \u0645\u0641\u0647\u0648\u0645. \u0648\u0639\u0646\u062f \u062a\u0643\u0631\u0627\u0631 \u0647\u0630\u0647 \u0627\u0644\u0643\u0644\u0645\u0627\u062a \u0645\u0631\u0629 \u0623\u062e\u0631\u0649\u060c \u0646\u062c\u062f \u0623\u0646 \u062a\u0637\u0631\u0642\u060c \u062a\u0637\u0648\u0631\u0627\u062a\u060c \u062a\u0642\u064a\u064a\u0645\u060c \u0642\u0648\u0629\u060c \u0627\u0644\u0635\u0644\u0629\u060c \u0627\u0644\u0623\u0633\u0644\u062d\u0629\u060c \u0645\u0646\u0638\u0645\u0629\u060c \u0648 \u0627\u0644\u0645\u0633\u062a\u0648\u064a\u064a\u0646 \u062c\u0645\u064a\u0639\u0647\u0627 \u062a\u0638\u0647\u0631 \u0645\u0634\u0643\u0644\u0627\u062a \u0645\u062a\u0643\u0631\u0631\u0629 \u0641\u064a \u0627\u0644\u0646\u0637\u0642 \u062a\u062c\u0639\u0644 \u0627\u0644\u0633\u0627\u0645\u0639 \u064a\u062f\u0631\u0643 \u0623\u0646 \u0627\u0644\u0646\u0638\u0627\u0645 \u0644\u0627 \u064a\u0645\u064a\u0632 \u0628\u064a\u0646 \u0627\u0644\u0637\u0627\u0621 \u0648\u0627\u0644\u062a\u0627\u0621\u060c \u0648\u0644\u0627 \u0628\u064a\u0646 \u0627\u0644\u0642\u0627\u0641 \u0648\u0627\u0644\u0643\u0627\u0641\u060c \u0648\u0644\u0627 \u0628\u064a\u0646 \u0627\u0644\u0633\u064a\u0646 \u0648\u0627\u0644\u0635\u0627\u062f\u060c \u0643\u0645\u0627 \u064a\u062e\u0637\u0626 \u0641\u064a \u0627\u0644\u062a\u0627\u0621 \u0627\u0644\u0645\u0631\u0628\u0648\u0637\u0629 \u0648\u064a\u0639\u062c\u0632 \u0639\u0646 \u0646\u0637\u0642 \u0627\u0644\u0645\u0633\u062a\u0648\u064a\u064a\u0646 \u0628\u0648\u0636\u0648\u062d.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nP-7i2QAC0JT"
   },
   "outputs": [],
   "source": [
    "#torch.manual_seed(2)\n",
    "#torch.manual_seed(9)\n",
    "#torch.manual_seed(12773624985526461855)\n",
    "torch.manual_seed(17779876142042974804)\n",
    "print(\"seed\", torch.initial_seed())\n",
    "#print(\"seed\", torch.seed())\n",
    "sentences = passage.split('.') # simple split by comma\n",
    "wavs = []\n",
    "s_prev = None\n",
    "for text in sentences:\n",
    "    if text.strip() == \"\": continue\n",
    "    text += '. \u00ab' # add it back\n",
    "    text = text.replace(\"(\", \", \").replace(\")\", \", \")\n",
    "    noise = torch.randn(1,1,256).to(device)\n",
    "    #wav = inference_100ms(text, noise, diffusion_steps=5, embedding_scale=1.2)\n",
    "    wav, s_prev = LFinference(text, s_prev, noise, alpha=0.7, diffusion_steps=10, embedding_scale=1.5)\n",
    "    #wav, s_prev = LFinference_trim_100ms(text, s_prev, noise, alpha=0.7, diffusion_steps=10, embedding_scale=1.5)\n",
    "    #wav, s_prev = LFinference_trim_100ms(text, s_prev, noise, alpha=0.4, diffusion_steps=10, embedding_scale=1.2, trim_ms=350, end_silence_ms=1000, noise_reduction_threshold=0.5, noise_estimage_energy_threshold=0.015, append_silence_energy_threshold=0.0015)\n",
    "    wavs.append(wav)\n",
    "display(ipd.Audio(np.concatenate(wavs), rate=24000, normalize=True))\n",
    "#display(ipd.Audio(_crossfade_concat(wavs, crossfade_ms=1100, sample_rate=24000), rate=24000, normalize=True))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM1x2mx2VnkYNFVlD+DFzmy",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}