log_dir: "Checkpoint"
save_freq: 10
device: "cuda"
epochs: 100
batch_size: 64
pretrained_model: ""
train_data: "Data/train_list.txt"
val_data: "Data/val_list.txt"
num_workers: 16

training:
  mixed_precision: true
  gradient_checkpointing: true
  gradient_checkpointing_use_reentrant: false
  ema_decay: 0.9997
  scheduler_metric: eval/vuv_f1
  early_stop:
    enabled: true
    min_lr: 0.000003
    patience: 9
    metric: eval/vuv_f1

model_params:
  num_class: 1
  sequence_model:
    model_type: bilstm
    num_layers: 4
    dropout: 0.1
    nhead: 8
    dim_feedforward: 1536
    max_len: 2048


optimizer_params:
  lr: 0.0003
  weight_decay: 0.0003
  scheduler_type: one_cycle

loss_params:
  lambda_f0: 0.1
  lambda_vuv: 0.5
  lambda_vuv_candidates:
    - 0.25
  f0_loss_scale: log_hz
  f0_huber_delta: 0.075
  f0_log_min_hz: 1.0
  f0_cents_reference_hz: 55.0
  silence_label_smoothing: 0.0
  silence_use_focal_loss: false
  silence_focal_gamma: 2.0
  silence_focal_alpha: null

dataset_params:
  mel_params:
    sample_rate: 24000
    win_len: 1024
    n_fft: 1024
    n_mels: 80
    hop_length: 300
  # Optional DataLoader overrides. Leave fields as null to accept the defaults.
  # When left unspecified the loader automatically switches to ``start_method:
  # spawn`` whenever a CUDA-enabled F0 backend is active so GPU extraction works
  # inside worker processes without manual tuning.
  dataloader:
    start_method: null
    persistent_workers: null
    prefetch_factor: null
  f0_params:
    bad_f0_threshold: 5
    zero_fill_value: 0.0
    # Ordered list of backend names to try when computing F0. Each entry must
    # match a key below in the ``backends`` dictionary and will be attempted in
    # sequence until one produces a valid contour.
    backend_order:
      # PyWorld's Harvest tracker prioritises accuracy and can optionally fall
      # back to a secondary algorithm (e.g. DIO) when it produces too few voiced
      # frames for a clip.
      - pyworld_harvest
      # PyWorld's DIO tracker is faster than Harvest and is a common baseline.
      - pyworld_dio
      # CREPE is a neural-network F0 estimator that works well on singing voice
      # and noisy material. Enable it when you have the dependency installed and
      # want a data-driven approach.
      - crepe
      # SwiftF0 runs an ONNX CNN over band-limited spectrogram features. It is
      # CPU-friendly and focuses on useful frequency ranges via learnable
      # filterbanks.
      - swiftf0
      # Praat accesses the classic signal-processing F0 algorithms via the
      # parselmouth bindings. The ``method`` parameter accepts values like
      # "ac" (autocorrelation) or "cc" (cross-correlation).
      - praat
      # Native parselmouth backend mirroring Praat's algorithm selection.
      - parselmouth
    backends:
      # Harvest configuration (PyWorld). Toggle ``enabled`` to include/exclude
      # the backend. ``algorithm`` can be "harvest", "dio", or "stonemask".
      # ``fallback`` specifies another PyWorld algorithm to try when the first
      # run returns mostly unvoiced frames. ``stonemask`` enables the refinement
      # pass after the main extraction.
      pyworld_harvest:
        type: pyworld
        enabled: false
        config:
          algorithm: harvest
          fallback: dio
          stonemask: true
      # DIO configuration (PyWorld). Set ``fallback`` to another algorithm name
      # (or null to disable) and toggle ``stonemask`` for optional refinement.
      pyworld_dio:
        type: pyworld
        enabled: false
        config:
          algorithm: dio
          fallback: null
          stonemask: true
      # TorchCrepe neural F0 (PyTorch implementation of CREPE). ``model`` accepts
      # "tiny", "small", "medium", or "full". ``step_size_ms`` controls the
      # analysis hop in milliseconds. ``fmin``/``fmax`` bound the search range.
      # ``batch_size`` controls GPU memory usage, ``pad``/``pad_mode`` mirror the
      # torchcrepe API, and ``return_periodicity`` exposes per-frame confidence
      # scores which can be thresholded via ``periodicity_threshold``. Set
      # ``median_filter_size`` > 1 to apply optional smoothing. ``device`` accepts
      # ``auto`` (prefer CUDA when available) or an explicit torch device string
      # like ``cpu`` or ``cuda:0``.
      crepe:
        type: crepe
        enabled: false
        config:
          model: full
          step_size_ms: null
          fmin: 50.0
          fmax: 1100.0
          batch_size: 12
          pad: true
          pad_mode: reflect
          return_periodicity: true
          periodicity_threshold: 0.4
          median_filter_size: 0
          device: auto
      # SwiftF0 uses an STFT front-end with learnable filterbanks followed by a
      # convolutional model. It runs on CPU via ONNX Runtime. Customize the
      # confidence threshold and frequency range to suppress noisy detections.
      swiftf0:
        type: swiftf0
        enabled: true
        config:
          confidence_threshold: 0.9
          fmin: 60.0
          fmax: 2000.0
          zero_unvoiced: true
          unvoiced_value: 0.0
      # Praat backend via parselmouth. ``method`` matches Praat's choices such
      # as "ac" (autocorrelation) or "cc" (cross-correlation). ``min_pitch`` and
      # ``max_pitch`` set the allowed frequency range in Hertz. The
      # ``silence_threshold`` and ``voicing_threshold`` values control
      # voiced/unvoiced detection sensitivity.
      praat:
        type: praat
        enabled: false
        config:
          method: ac
          min_pitch: 40.0
          max_pitch: 1100.0
          silence_threshold: 0.03
          voicing_threshold: 0.45
      # Native parselmouth wrapper. Accepts the same ``method``/threshold
      # options as Praat but can be configured independently if you want a
      # different parameter set.
      parselmouth:
        type: parselmouth
        enabled: false
        config:
          method: ac
          min_pitch: 40.0
          max_pitch: 1100.0
          silence_threshold: 0.03
          voicing_threshold: 0.45
  synthetic_data:
    enabled: true
    ratio: 0.25
    apply_to_validation: false
    pitch_shift:
      enabled: true
      semitones: [-4, -2, -1, 1, 2, 4]
      gain_db_range: [-6.0, 3.0]
      min_voiced_fraction: 0.05
      resample_type: kaiser_best
    world_vocoder:
      enabled: true
      duration:
        min: 0.6
        max: 1.5
      pitch_range: [110.0, 320.0]
      gain_db_range: [-18.0, -6.0]
      noise_db: -60.0
      modulation:
        vibrato_probability: 0.5
        vibrato_semitones: 0.4
        vibrato_rate_range: [4.0, 6.0]
  
